{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THaW Project\n",
    "#This program is meant to establish the accuracy of predicting device name from the data collected by MSU\n",
    "#6/12/2019\n",
    "#Code Written By: Manzi Bryan with a lot of help from https://www.kaggle.com/nageshnaik/iris-dataset-classfication-using-naive-bayes\n",
    "# This code should be submitted for review \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import *\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "import operator\n",
    "import time\n",
    "import seaborn as sns\n",
    "from pprint import pprint# Look at parameters used by our current forest\n",
    "\n",
    "target = 'Model'\n",
    "\n",
    "\n",
    "# This method is meant to build a Random Forest Classifier given a dataframe with devices as targets\n",
    "# The dontTrainOn parameter is meant to tell the classifier to leave one tenth of one device out of training\n",
    "\n",
    "# This method is meant to build a Random Forest Classifier given a dataframe with devices as targets\n",
    "\n",
    "def makeClassifier(df, functionName, clf, labels, f1Dataframe = None, i= None,):\n",
    "    \n",
    "    inTestingMode = not (f1Dataframe == None and i == None)\n",
    "    devices = df[target].unique()\n",
    "    copydf = df.copy()\n",
    "    \n",
    "    copydf[target].replace(devices, range(0, len(devices)), inplace=True)\n",
    "        \n",
    "    Y = copydf[target].tolist()\n",
    "    \n",
    "#     print(\"There are \" + str(len(devices)) + \" devices\")\n",
    "    \n",
    "    #Remove labelling columns from the index\n",
    "    copydf = copydf.drop(columns= labels)\n",
    "    X = copydf.values\n",
    "    \n",
    "    \n",
    "    #One tenth of the data as test\n",
    "    validation_size = 0.1\n",
    "    \n",
    "    seed = 7\n",
    "    \n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, \n",
    "                                                    test_size=validation_size, random_state=seed)\n",
    "    \n",
    "    scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_macro': 'recall_macro',\n",
    "            'f1_macro' : 'f1_macro'}\n",
    "#     scoring = {\n",
    "#             'acc': 'accuracy',\n",
    "#             'f1_macro' : 'f1_macro'}\n",
    "\n",
    "    \n",
    "    #Fitting the training set\n",
    "    clf.fit(X_train, Y_train) \n",
    "    \n",
    "   \n",
    "    #Model Performance\n",
    "    #setting performance parameters\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=10, random_state=seed) #same number of samples from each \n",
    "\n",
    "    #calling the cross validation function\n",
    "    \n",
    "    cv_results = cross_validate(clf, X_train, Y_train, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    if not inTestingMode:\n",
    "        filename = functionName  + 'Model.sav' # Save Classifier\n",
    "        print(functionName)\n",
    "        pickle.dump(clf, open(filename, 'wb'))\n",
    "        for metric in cv_results.keys():\n",
    "            print(metric + \": \" + str(cv_results[metric].mean()))\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        f1Dataframe['Classifier'][i] = functionName\n",
    "        f1Dataframe['f1'][i] = str(cv_results['test_f1_macro'].mean())\n",
    "    \n",
    "    return clf\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneClassifier(df, labels):\n",
    "    n_est = 15\n",
    "    depth = 15\n",
    "    name = 'RandomForest'\n",
    "    name2 = 'KNN'\n",
    "    name3 = 'DecisionTree'\n",
    "    name4 = 'GNB'\n",
    "    \n",
    "    classifier = RandomForestClassifier(bootstrap= True, max_depth= 30, max_features= 3, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 30, random_state=42)\n",
    "    classifier3 = DecisionTreeClassifier(max_depth= 21, max_features= 3, min_samples_leaf= 3, min_samples_split= 3, random_state=42)\n",
    "    classifier2 = KNeighborsClassifier(algorithm= 'auto', leaf_size= 1, n_neighbors= 11, weights= 'distance')\n",
    "    classifier4 = GaussianNB()\n",
    "    \n",
    "\n",
    "    devices = df[target].unique()\n",
    "#     df = pd.read_excel(path)\n",
    "\n",
    "    df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)#Remove unnecessary columns from the dataframe\n",
    "    makeClassifier(df, name, classifier, labels)\n",
    "    makeClassifier(df, name2, classifier2, labels)\n",
    "    makeClassifier(df, name3, classifier3, labels)\n",
    "    makeClassifier(df, name4, classifier4, labels)\n",
    "    return devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeManyClassifiers(df, labels):\n",
    "    \n",
    "    functions = {}\n",
    "    f1Dataframe = pd.DataFrame(index = range(0, 10000), columns=['Classifier', 'f1'])\n",
    "    # Grid search from 1 to 100\n",
    "    for depthDivideBy5 in range(1, 21):\n",
    "        for n_estDivideBy5 in range(1, 21):\n",
    "            depth = depthDivideBy5 * 5\n",
    "            n_est = n_estDivideBy5 * 5\n",
    "            functions['RandomForest d=' + str(depth) + ' n_est=' + str(n_est)] = RandomForestClassifier(n_estimators=n_est, max_depth=depth)\n",
    "    \n",
    "#     functions['RandomForest d=14 n_est=25'] = RandomForestClassifier(n_estimators=14, max_depth=25)\n",
    "#     functions['RandomForest d=22 n_est=55'] = RandomForestClassifier(n_estimators=22, max_depth=55)\n",
    "    devices = df[target].unique()\n",
    "    i = 0\n",
    "    for functionName in functions:\n",
    "        df = pd.read_excel(path)\n",
    "        \n",
    "        df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)#Remove unnecessary columns from the index\n",
    "#         df.drop(df.columns[df.columns.str.contains('Bursts',case = False)],axis = 1, inplace = True)#Remove unnecessary columns from \n",
    "        makeClassifier(df, functionName, functions[functionName], labels, f1Dataframe, i)\n",
    "        i += 1\n",
    "    f1Dataframe.to_excel('./BestClassifiers.xlsx')\n",
    "    return devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to read...\n",
      "...read\n",
      "RandomForest\n",
      "fit_time: 0.21381311416625975\n",
      "score_time: 0.02028179168701172\n",
      "test_acc: 0.9622260356424415\n",
      "train_acc: 0.9997077588658237\n",
      "test_prec_macro: 0.9534514935656728\n",
      "train_prec_macro: 0.9996202613145421\n",
      "test_rec_macro: 0.9378556184613899\n",
      "train_rec_macro: 0.9994147517576847\n",
      "test_f1_macro: 0.9439252044846024\n",
      "train_f1_macro: 0.9995158616991724\n",
      "\n",
      "\n",
      "KNN\n",
      "fit_time: 0.012168788909912109\n",
      "score_time: 0.10919499397277832\n",
      "test_acc: 0.917951191701933\n",
      "train_acc: 1.0\n",
      "test_prec_macro: 0.9084968704712738\n",
      "train_prec_macro: 1.0\n",
      "test_rec_macro: 0.8770359203623975\n",
      "train_rec_macro: 1.0\n",
      "test_f1_macro: 0.885162085503354\n",
      "train_f1_macro: 1.0\n",
      "\n",
      "\n",
      "DecisionTree\n",
      "fit_time: 0.011923789978027344\n",
      "score_time: 0.003454756736755371\n",
      "test_acc: 0.9222156287481991\n",
      "train_acc: 0.9685697302674301\n",
      "test_prec_macro: 0.8861169520956841\n",
      "train_prec_macro: 0.9556353088044978\n",
      "test_rec_macro: 0.8790130948046262\n",
      "train_rec_macro: 0.9501151198958393\n",
      "test_f1_macro: 0.8778326710622529\n",
      "train_f1_macro: 0.952492710881456\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "fit_time: 0.00397794246673584\n",
      "score_time: 0.007487988471984864\n",
      "test_acc: 0.5942613596084588\n",
      "train_acc: 0.5948317851614792\n",
      "test_prec_macro: 0.499514824133116\n",
      "train_prec_macro: 0.5058744329138889\n",
      "test_rec_macro: 0.5350264994183649\n",
      "train_rec_macro: 0.5341727060316128\n",
      "test_f1_macro: 0.4521340282364469\n",
      "train_f1_macro: 0.45265752589058944\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\brnma\\Miniconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path= 'efficientTrain.xlsx'\n",
    "    \n",
    "    print(\"About to read...\")\n",
    "    traindf = pd.read_excel(path) \n",
    "    print(\"...read\")\n",
    "    traindf = traindf.reindex(sorted(traindf.columns), axis=1)\n",
    "    \n",
    "    labels = ['Device','Model','App','Distance', 'Bursts']\n",
    "    \n",
    "#     duplicated = ['iHealth Blood Pressure', 'Fever Sense', 'iHealth gluco', 'Portable_ECG', 'Pyle Health']\n",
    "    \n",
    "#     df_filtered0 = traindf[traindf['Model'] == duplicated[0]] \n",
    "#     df_filtered1 = traindf[traindf['Model'] == duplicated[1]] \n",
    "#     df_filtered2 = traindf[traindf['Model'] == duplicated[2]] \n",
    "#     df_filtered3 = traindf[traindf['Model'] == duplicated[3]] \n",
    "#     df_filtered4 = traindf[traindf['Model'] == duplicated[4]] \n",
    "#     frames = [df_filtered0, df_filtered1, df_filtered2, df_filtered3, df_filtered4]\n",
    "    \n",
    "#     result = pd.concat(frames)\n",
    "    \n",
    "#     makeManyClassifiers(, labels) \n",
    "    makeOneClassifier(traindf, labels)\n",
    "#     print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHisto(confidences, deviceName):\n",
    "    # Make Histograms\n",
    "    bins = np.linspace(confidences[0], confidences[-1])\n",
    "    \n",
    "    num_bins = 100 # <-- Change here - Specify total number of bins for histogram\n",
    "    plt.hist(confidences, bins=np.linspace(np.min(confidences), np.max(confidences), num=num_bins)) #<-- Change here.  Note the use of ravel.\n",
    "    plt.savefig(deviceName + ' Histogram')\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumerical(devices, y):\n",
    "    i = 0\n",
    "    \n",
    "    for device in devices:\n",
    "        if device == y[0]:\n",
    "            return [i] * len(y)\n",
    "        i += 1\n",
    "\n",
    "def makePrediction(model, unseen, devices, numReadings, deviceName, labels):\n",
    "    loadedModel = pickle.load(open(model, 'rb'))\n",
    "    unseen = unseen.reindex(sorted(unseen.columns), axis=1)\n",
    "    \n",
    "    unseen.drop(unseen.columns[unseen.columns.str.contains('Unname',case = False)],axis = 1, inplace = True)\n",
    "    \n",
    "    y = unseen[target].tolist() #unseen should only contain one device, hence y is a list of the same device repeated\n",
    "    \n",
    "    \n",
    "    unseen = unseen.drop(columns= labels)\n",
    "    predictions = loadedModel.predict(unseen)\n",
    "    \n",
    "    predictions_proba = loadedModel.predict_proba(unseen)\n",
    "    i = 0\n",
    "    other = 0\n",
    "    confidences = []\n",
    "    for i in range(0, len(predictions_proba)):\n",
    "        confidences.append(round(predictions_proba[i].max(), 3))\n",
    "        \n",
    "    print(len(predictions_proba))\n",
    "    confidences.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
