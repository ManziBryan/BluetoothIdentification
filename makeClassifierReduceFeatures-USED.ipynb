{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to read...\n",
      "...read\n",
      "final features used are\n",
      "['Amplitude__count_above_mean', 'Amplitude__index_mass_quantile__q_0.4', 'Amplitude__index_mass_quantile__q_0.7', 'Amplitude__longest_strike_above_mean', 'Amplitude__number_cwt_peaks__n_1', 'Amplitude__number_peaks__n_1', 'Amplitude__number_peaks__n_10', 'Amplitude__number_peaks__n_3', 'Amplitude__number_peaks__n_5', 'Amplitude__ratio_beyond_r_sigma__r_0.5', 'Amplitude__ratio_beyond_r_sigma__r_1', 'Device', 'Model', 'App', 'Distance', 'Bursts']\n",
      "throwaway features are \n",
      "['Device', 'Model', 'App', 'Distance', 'Bursts', 'Amplitude__symmetry_looking__r_0.1', 'Amplitude__last_location_of_maximum', 'Amplitude__augmented_dickey_fuller__attr_\"usedlag\"', 'Amplitude__augmented_dickey_fuller__attr_\"teststat\"', 'Amplitude__autocorrelation__lag_5', 'Amplitude__fft_aggregated__aggtype_\"skew\"', 'Amplitude__autocorrelation__lag_8', 'Amplitude__ratio_beyond_r_sigma__r_6', 'Amplitude__autocorrelation__lag_4', 'Amplitude__cid_ce__normalize_False', 'Amplitude__autocorrelation__lag_6', 'Amplitude__autocorrelation__lag_9', 'Burst-Top Stdev', 'Amplitude__fft_aggregated__aggtype_\"centroid\"', 'Burst-Top Height', 'Amplitude__autocorrelation__lag_3', 'Amplitude__ratio_beyond_r_sigma__r_2', 'Amplitude__ratio_beyond_r_sigma__r_3', 'Amplitude__spkt_welch_density__coeff_2', 'Amplitude__autocorrelation__lag_1', 'Amplitude__standard_deviation', 'Amplitude__index_mass_quantile__q_0.3', 'Amplitude__binned_entropy__max_bins_10', 'Amplitude__number_peaks__n_50', 'Amplitude__ratio_beyond_r_sigma__r_2.5', 'Amplitude__kurtosis', 'Amplitude__cid_ce__normalize_True', 'Amplitude__spkt_welch_density__coeff_5', 'Amplitude__skewness', 'Amplitude__number_cwt_peaks__n_5', 'Amplitude__spkt_welch_density__coeff_8', 'Amplitude__variance', 'Amplitude__count_below_mean', 'Amplitude__absolute_sum_of_changes', 'Amplitude__fft_aggregated__aggtype_\"variance\"']\n"
     ]
    }
   ],
   "source": [
    "#THaW Project\n",
    "#This program is meant to establish the accuracy of predicting device name from the data collected by MSU\n",
    "#6/12/2019\n",
    "#Code Written By: Manzi Bryan with a lot of help from https://www.kaggle.com/nageshnaik/iris-dataset-classfication-using-naive-bayes\n",
    "# This code should be submitted for review \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import *\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from pprint import pprint# Look at parameters used by our current forest\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "target = 'Device'\n",
    "\n",
    "\n",
    "# This method is meant to build a Random Forest Classifier given a dataframe with devices as targets\n",
    "# The dontTrainOn parameter is meant to tell the classifier to leave one tenth of one device out of training\n",
    "\n",
    "# This method is meant to build a Random Forest Classifier given a dataframe with devices as targets\n",
    "\n",
    "def makeClassifier(df, functionName, clf, labels, f1Dataframe = None, i= None,):\n",
    "    \n",
    "    inTestingMode = not (f1Dataframe == None and i == None)\n",
    "    devices = df[target].unique()\n",
    "    copydf = df.copy()\n",
    "    \n",
    "    copydf[target].replace(devices, range(0, len(devices)), inplace=True)\n",
    "        \n",
    "    Y = copydf[target].tolist()\n",
    "    \n",
    "    \n",
    "    #Remove labelling columns from the index\n",
    "    copydf = copydf.drop(columns= labels)\n",
    "    X = copydf.values\n",
    "    \n",
    "    \n",
    "    #One tenth of the data as test\n",
    "    validation_size = 0.1\n",
    "    \n",
    "    seed = 7\n",
    "    \n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, \n",
    "                                                    test_size=validation_size, random_state=seed)\n",
    "    \n",
    "    scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_macro': 'recall_macro',\n",
    "            'f1_macro' : 'f1_macro'}\n",
    "\n",
    "    \n",
    "    #Fitting the training set\n",
    "    selector = RFE(clf, n_features_to_select=1, step=1)\n",
    "    selector = selector.fit(X_train, Y_train)\n",
    "    \n",
    "    clf.fit(X_train, Y_train) \n",
    "    \n",
    "   \n",
    "    #Model Performance\n",
    "#     #setting performance parameters\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=10, random_state=seed) #same number of samples from each \n",
    "\n",
    "    #calling the cross validation function\n",
    "    \n",
    "    cv_results = cross_validate(clf, X_train, Y_train, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    if not inTestingMode:\n",
    "        filename = functionName  + 'Model.sav' # Save Classifier\n",
    "#         pickle.dump(clf, open(filename, 'wb'))\n",
    "#         for metric in cv_results.keys():\n",
    "#             print(metric + \": \" + str(cv_results[metric].mean()))\n",
    "#         print('\\n')\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        f1Dataframe['Classifier'][i] = functionName\n",
    "        f1Dataframe['f1'][i] = str(cv_results['test_f1_macro'].mean())\n",
    "    \n",
    "    return selector.ranking_, cv_results['test_acc'].mean(), cv_results['test_f1_macro'].mean(), copydf.columns\n",
    "    \n",
    "def makeOneClassifier(df, labels):\n",
    "    n_est = 15\n",
    "    depth = 15\n",
    "    name = 'RandomForest d=' + str(depth) + ' n_est=' + str(n_est)\n",
    "    classifier = RandomForestClassifier(n_estimators=n_est, max_depth=depth, random_state=42)\n",
    "    \n",
    "\n",
    "    devices = df[target].unique()\n",
    "#     df = pd.read_excel(path)\n",
    "\n",
    "    df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)#Remove unnecessary columns from the dataframe\n",
    "    numFeatures = []\n",
    "    accuracys = []\n",
    "    f1s = []\n",
    "    ranking, accuracy, f1, columns = makeClassifier(df, name, classifier, labels)\n",
    "    accuracys.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "    i = 0\n",
    "    while i < 35:\n",
    "        worstFeature = np.argmax(ranking) # returns the indices of the largest value\n",
    "        labels.append(columns[worstFeature])\n",
    "        ranking = np.delete(ranking, worstFeature) \n",
    "        columns = columns.delete(worstFeature)\n",
    "#         ranking, accuracy, f1, columns = makeClassifier(df, name, classifier, labels)\n",
    "#         accuracys.append(accuracy)\n",
    "#         f1s.append(f1)\n",
    "#         print(\"accuracys = \" + str(accuracys))\n",
    "#         print(\"f1s = \" + str(f1s))\n",
    "        i += 1\n",
    "    \n",
    "    print(\"final features used are\")\n",
    "    final_table_columns = list(columns)\n",
    "    final_table_columns += ['Device','Model','App','Distance', 'Bursts'] # Create an efficient training \n",
    "    print(final_table_columns)\n",
    "    efficientTrain = df[df.columns.intersection(final_table_columns)]\n",
    "    efficientTrain.to_excel('efficientTrain.xlsx')\n",
    "    \n",
    "    testPath= r'C:\\Users\\brnma\\test.xlsx'\n",
    "    testdf = pd.read_excel(testPath)\n",
    "    efficientTest = testdf[testdf.columns.intersection(final_table_columns)]\n",
    "    efficientTest.to_excel('efficientTest.xlsx')\n",
    "    \n",
    "    \n",
    "    print(\"throwaway features are \")\n",
    "    print(labels)\n",
    "    \n",
    "    return devices\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path=r'C:\\Users\\brnma\\train.xlsx'\n",
    "    \n",
    "    print(\"About to read...\")\n",
    "    traindf = pd.read_excel(path) \n",
    "    print(\"...read\")\n",
    "    traindf = traindf.reindex(sorted(traindf.columns), axis=1)\n",
    "    traindf = traindf.drop(['Burst Width', 'Amplitude__length'], axis=1)\n",
    "    \n",
    "    labels = ['Device','Model','App','Distance', 'Bursts']\n",
    "    makeOneClassifier(traindf, labels)\n",
    "#     print(\"Done\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "0.9472013911202929\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5, forward=True)\n",
    "x = list(range(0, 45))\n",
    "f1s = [0.9193162379906983, 0.9195561288407166, 0.9173424482182865, 0.9182753574862857, 0.9214811293728985, 0.9217425502928418, 0.9216548015461272, 0.9223759848605646, 0.9175566483826649, 0.9173319445306719, 0.9258443647727148, 0.9182319152314617, 0.9202790946565116, 0.914789946990972, 0.9213143072885248, 0.9217401921226358, 0.9174140904595489, 0.9217002740885633, 0.9240448410164573, 0.9191921075094471, 0.923080179870835, 0.9217376736887806, 0.918969771190772, 0.924501725810414, 0.9168913343086516, 0.9211066051927028, 0.9211482866442575, 0.9230830944438028, 0.9239474531025509, 0.9237557941743134, 0.9231374162288628, 0.9227230243056359, 0.9218518600996817, 0.9252847896144845, 0.9145614406144027, 0.9193265296081391, 0.9104086927312199, 0.9132199750507745, 0.9053480269129504, 0.9129993168860334, 0.9018373898097938, 0.8901587591029665, 0.8672729747875227, 0.8548041953336565, 0.8171489629342832]\n",
    "accuracys = [0.9415575031383747, 0.9417484885755025, 0.9370568136759168, 0.9396994572418077, 0.9434604358340893, 0.9412041130722442, 0.9421685483472597, 0.9436754283981695, 0.9411910390902797, 0.939530085409468, 0.9457118571646266, 0.9415732154457708, 0.9440321166726703, 0.9397243543699627, 0.9413574479735516, 0.9415532719654017, 0.941035365699437, 0.9453243556379458, 0.9449474514134083, 0.9406329016659407, 0.944992398615119, 0.9430493512411993, 0.9410219677360165, 0.9462773132047904, 0.943817863346587, 0.9428670915150983, 0.9426868120408374, 0.9451438320781325, 0.9455195291834354, 0.9455041847832033, 0.9464579873050495, 0.9451482787700325, 0.9470147622831716, 0.9472013911202929, 0.9408340552691096, 0.9426805514903507, 0.9365035468508601, 0.9383837449589049, 0.9346288361840008, 0.9365139348658283, 0.931054045140011, 0.9155000372923503, 0.8953858620624204, 0.8839225629734541, 0.8568972169253488]\n",
    "max_value = max(accuracys)\n",
    "max_index = accuracys.index(max_value)\n",
    "print(max_index)\n",
    "print(max_value)\n",
    "# accuracys.reverse()\n",
    "# f1s.reverse()\n",
    "\n",
    "# label_acc= \"Accuracy\"\n",
    "\n",
    "# line1, = ax.plot(x, accuracys, label=label_acc)\n",
    "\n",
    "# label_f1= \"F1\"\n",
    "# line2, = ax.plot(x, f1s, label=label_f1)\n",
    "\n",
    "# print(accuracys[9])\n",
    "# print(f1s[9])\n",
    "# plt.ylabel('Performance')\n",
    "# plt.xlabel('Number of Features')\n",
    "\n",
    "# first_legend = plt.legend(handles=[line1, line2], loc='lower right')\n",
    "\n",
    "# # Add the legend manually to the current Axes.\n",
    "\n",
    "\n",
    "# ax.set_title('Perfomance of Random Forest as Number of Features Varied')\n",
    "\n",
    "# ax = plt.gca().add_artist(first_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
